{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.463987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar Saxena\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1000/60000 (2%)]\tLoss: 0.459788\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 0.456850\n",
      "Train Epoch: 0 [3000/60000 (5%)]\tLoss: 0.448534\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.444970\n",
      "Train Epoch: 0 [5000/60000 (8%)]\tLoss: 0.433937\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.428444\n",
      "Train Epoch: 0 [7000/60000 (12%)]\tLoss: 0.421800\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.420536\n",
      "Train Epoch: 0 [9000/60000 (15%)]\tLoss: 0.407488\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.401619\n",
      "Train Epoch: 0 [11000/60000 (18%)]\tLoss: 0.383985\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.385909\n",
      "Train Epoch: 0 [13000/60000 (22%)]\tLoss: 0.367685\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.357322\n",
      "Train Epoch: 0 [15000/60000 (25%)]\tLoss: 0.354800\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.344937\n",
      "Train Epoch: 0 [17000/60000 (28%)]\tLoss: 0.317874\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.325523\n",
      "Train Epoch: 0 [19000/60000 (32%)]\tLoss: 0.312371\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.300493\n",
      "Train Epoch: 0 [21000/60000 (35%)]\tLoss: 0.284678\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.279915\n",
      "Train Epoch: 0 [23000/60000 (38%)]\tLoss: 0.273995\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.259390\n",
      "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 0.248242\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.259923\n",
      "Train Epoch: 0 [27000/60000 (45%)]\tLoss: 0.253430\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.239824\n",
      "Train Epoch: 0 [29000/60000 (48%)]\tLoss: 0.235828\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.223267\n",
      "Train Epoch: 0 [31000/60000 (52%)]\tLoss: 0.218804\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.231665\n",
      "Train Epoch: 0 [33000/60000 (55%)]\tLoss: 0.208391\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.215693\n",
      "Train Epoch: 0 [35000/60000 (58%)]\tLoss: 0.194944\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.211643\n",
      "Train Epoch: 0 [37000/60000 (62%)]\tLoss: 0.201194\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.206693\n",
      "Train Epoch: 0 [39000/60000 (65%)]\tLoss: 0.178693\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.189892\n",
      "Train Epoch: 0 [41000/60000 (68%)]\tLoss: 0.212065\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.163855\n",
      "Train Epoch: 0 [43000/60000 (72%)]\tLoss: 0.194244\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.179185\n",
      "Train Epoch: 0 [45000/60000 (75%)]\tLoss: 0.193514\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.175958\n",
      "Train Epoch: 0 [47000/60000 (78%)]\tLoss: 0.171314\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.184566\n",
      "Train Epoch: 0 [49000/60000 (82%)]\tLoss: 0.169168\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.173095\n",
      "Train Epoch: 0 [51000/60000 (85%)]\tLoss: 0.170654\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.180451\n",
      "Train Epoch: 0 [53000/60000 (88%)]\tLoss: 0.177799\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.162044\n",
      "Train Epoch: 0 [55000/60000 (92%)]\tLoss: 0.184177\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.172284\n",
      "Train Epoch: 0 [57000/60000 (95%)]\tLoss: 0.166911\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.173016\n",
      "Train Epoch: 0 [59000/60000 (98%)]\tLoss: 0.164506\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 7022/10000 (70%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.134346\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.160957\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.151177\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.180771\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.163577\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.159409\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.147783\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.146494\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.145034\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.148703\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.156519\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.162606\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.156798\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.154983\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.134317\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.146054\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.141921\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.141974\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.133264\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.138726\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.128951\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.135860\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.135974\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.147048\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.133893\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.138542\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.142244\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.141475\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.160226\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.165277\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.126781\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.145825\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.131348\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.149911\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.134741\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.121804\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.117041\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.135380\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.120232\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.112772\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.129354\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.132407\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.134799\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.141328\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.126150\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.120321\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.150171\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.132985\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.147148\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.139221\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.133983\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.135864\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.133723\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.113615\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.146007\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.128884\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.133082\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.141366\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.139387\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.137167\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 7697/10000 (77%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.121006\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.122041\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.115456\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.110108\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.110720\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.119742\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.117784\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.120512\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.135239\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.141064\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.132883\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.127634\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.128733\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.114810\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.138479\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.123055\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.120951\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.117144\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.118366\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.124780\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.117820\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.134507\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.122799\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.113404\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.102003\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.115511\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.111352\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.117845\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.117237\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.124051\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.128558\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.110755\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.103774\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.123335\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.107741\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.121961\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.112922\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.117406\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.095180\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.112241\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.098190\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.112549\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.114800\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.134405\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.109766\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.110944\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.128823\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.110504\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.116279\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.109388\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.108510\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.103601\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.088637\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.116937\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.094636\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.084824\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.109805\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.118355\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.114550\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.107081\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 8003/10000 (80%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.108903\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.101805\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.113952\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.091805\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.092500\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.122618\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.109129\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.119491\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.118267\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.105439\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.109962\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.127949\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.096942\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.135969\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.100563\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.086273\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.111536\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.102838\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.099099\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.090628\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.080955\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.093927\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.106407\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.085139\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.108940\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.110543\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.115376\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.105460\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.100162\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.099614\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.102431\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.104808\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.099083\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.118986\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.109162\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.124502\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.103741\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.093420\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.124719\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.097280\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.122272\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.096928\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.091958\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.119985\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.123111\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.106509\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.111695\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.107524\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.096805\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.133972\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.104349\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.099908\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.129344\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.105126\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.086307\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.104350\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.092101\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.097300\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.094419\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.093548\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 8104/10000 (81%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.108365\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.105203\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.095459\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.091094\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.099989\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.105147\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.107337\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.094664\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.096955\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.096340\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.101985\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.087259\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.070915\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.088955\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.108823\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.111357\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.094223\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.094288\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.090358\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.092433\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.085038\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.107117\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.082247\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.088491\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.091069\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.113499\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.099800\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.098946\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.107380\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.109566\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.093971\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.111234\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.100258\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.071873\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.100899\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.100516\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.109111\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.112737\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.115688\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.124535\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.082818\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.087565\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.091258\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.104521\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.101347\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.088496\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.105523\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.096204\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.097476\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.087877\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.075605\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.115569\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.096752\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.107361\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.074712\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.097643\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.107056\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.099053\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.136386\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.089282\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 8185/10000 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "def create_nn(batch_size=200, learning_rate=0.001, epochs=5,\n",
    "              log_interval=5):\n",
    "\n",
    "    #Loading the dataset into the train and test tensors\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        # Create a neural network of your choice\n",
    "        # You can begin with 2 hidden layers and one output layer \n",
    "        # With 200 units for each hidden layer and 10 output units\n",
    "        # insert ReLU activations between the hidden layers\n",
    "        # and softmax for the output\n",
    "       \n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(28 * 28, 200)\n",
    "            self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(x)\n",
    "\n",
    "    net = Net()\n",
    "    print(net)\n",
    "\n",
    "    # create a stochastic gradient descent optimizer\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # create a loss function\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    #global_step = tf.Variable(0, trainable=False)\n",
    "    #starter_learning_rate = 0.05\n",
    "    #learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "     #                                  1000, 0.96, staircase=True)\n",
    "\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True).minimize(cost, global_step=global_step)\n",
    "    \n",
    "    # create a stochastic gradient descent optimizer/ try different optimizers\n",
    "    # here like ADAM AdaGrad Momentum\n",
    "\n",
    "\n",
    "    # create a loss function use an NLL loss that mimics crossentropy\n",
    "\n",
    "\n",
    "    # run the main training loop\n",
    "    # Every iteration over the complete training set is called an epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss = 0\n",
    "        # Train over the dataset for each minibatch\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "            data = data.view(-1, 28*28)\n",
    "            optimizer.zero_grad()\n",
    "            net_out = net(data)\n",
    "            loss = criterion(net_out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader),\n",
    "                    loss.data[0]/log_interval))\n",
    "\n",
    "                train_loss = 0\n",
    "\n",
    "        # run a test loop\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data = data.view(-1, 28 * 28)\n",
    "            net_out = net(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(net_out, target).data[0]\n",
    "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data).sum()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
